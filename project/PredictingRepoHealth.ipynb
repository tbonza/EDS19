{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The `RepoHealth` notebook reviews descriptive statistics and finds patterns which seem to be\n",
    "shared by healthy and unhealthy repositories. This `PredictingRepoHealth` notebook focuses\n",
    "solely on predicting time series. \n",
    "\n",
    "$v(t) = \\alpha + \\beta_1 x_1 + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tylerbrown/code/author_2019-04-20_0.parquet\r\n",
      "/Users/tylerbrown/code/commit_file_2019-04-20_0.parquet\r\n",
      "/Users/tylerbrown/code/commit_file_2019-04-20_1.parquet\r\n",
      "/Users/tylerbrown/code/contrib_2019-04-20_0.parquet\r\n",
      "/Users/tylerbrown/code/features_apache__LOGDF__attic-lucy.parquet\r\n",
      "/Users/tylerbrown/code/features_apache__LOGDF__attic-wink.parquet\r\n",
      "/Users/tylerbrown/code/features_apache__LOGDF__lucene-solr.parquet\r\n",
      "/Users/tylerbrown/code/features_apache__LOGDF__spark.parquet\r\n",
      "/Users/tylerbrown/code/features_docker__LOGDF__docker-ce.parquet\r\n",
      "/Users/tylerbrown/code/features_torvalds__LOGDF__linux.parquet\r\n",
      "/Users/tylerbrown/code/info_2019-04-20_0.parquet\r\n",
      "/Users/tylerbrown/code/meta_2019-04-20_0.parquet\r\n",
      "/Users/tylerbrown/code/target_apache__LOGDF__attic-lucy.parquet\r\n",
      "/Users/tylerbrown/code/target_apache__LOGDF__attic-wink.parquet\r\n",
      "/Users/tylerbrown/code/target_apache__LOGDF__lucene-solr.parquet\r\n",
      "/Users/tylerbrown/code/target_apache__LOGDF__spark.parquet\r\n",
      "/Users/tylerbrown/code/target_docker__LOGDF__docker-ce.parquet\r\n",
      "/Users/tylerbrown/code/target_torvalds__LOGDF__linux.parquet\r\n"
     ]
    }
   ],
   "source": [
    "ls ~/code/*.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Databases have been consolidated and switched to Parquet files with\n",
    "no more than 2e6 records in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2327964, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits = pd.read_parquet('/Users/tylerbrown/code/commit_file_2019-04-20_0.parquet', 'pyarrow').append(\n",
    "    pd.read_parquet('/Users/tylerbrown/code/commit_file_2019-04-20_1.parquet', 'pyarrow')\n",
    ")\n",
    "commits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928779, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_parquet('/Users/tylerbrown/code/meta_2019-04-20_0.parquet', 'pyarrow')\n",
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928779, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = pd.read_parquet('/Users/tylerbrown/code/author_2019-04-20_0.parquet')\n",
    "author.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Use these later in a Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceleration(v):\n",
    "    \"\"\" Convert velocity vector to acceleration \"\"\"\n",
    "    v1 = [v[i] - v[i-1] if i > 0 else v[i] for i in range(v.shape[0])]\n",
    "    return v1\n",
    "\n",
    "def acceleration_per_repo(df, period):\n",
    "   \n",
    "    cols = ['authored','owner_name', 'project_name', \n",
    "            'lines_added', 'lines_subtracted']\n",
    "    \n",
    "    per = df.authored.dt.to_period(period)\n",
    "    grp = [per,'owner_name', 'project_name']\n",
    "    \n",
    "    dfgrp = df[cols].groupby(grp).sum()\n",
    "    dfgrp['velocity'] = dfgrp.lines_added - dfgrp.lines_subtracted\n",
    "    dfgrp = dfgrp.reset_index()\n",
    "    \n",
    "    igrp = ['owner_name', 'project_name']\n",
    "    dfgrp['acceleration'] = 0.0\n",
    "    for i, row in dfgrp[igrp].groupby(igrp).count().reset_index().iterrows():\n",
    "        \n",
    "        subdf = dfgrp[(dfgrp.owner_name == row.owner_name) & (dfgrp.project_name == row.project_name)]\n",
    "        v = subdf.velocity.values\n",
    "        acc = acceleration(v)\n",
    "        dfgrp.loc[(dfgrp.owner_name == row.owner_name) & \n",
    "           (dfgrp.project_name == row.project_name), 'acceleration'] = acc\n",
    "        \n",
    "    return dfgrp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We need to set up a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2327964, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create working table\n",
    "\n",
    "df = pd.merge(pd.merge(meta, commits), author)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weird things didn't happen: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Weird things didn't happen: {}\".format(df.shape[0] == commits.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ts'] = pd.to_datetime(df.authored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We need to create some features to predict velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['commit_hash', 'owner_name', 'project_name', 'file_id', 'modified_file',\n",
       "       'lines_added', 'lines_subtracted', 'name', 'email', 'authored', 'ts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_authors(df, period: str):\n",
    "    \"\"\" Number of authors in a given time period. \"\"\"\n",
    "    per = df.ts.dt.to_period(period)\n",
    "    \n",
    "    cols = ['name','owner_name', 'project_name']\n",
    "    grp = [per, 'owner_name', 'project_name']\n",
    "    result = df[cols].groupby(grp).count()\n",
    "    result.columns = ['num_authors']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_mentors(df, period:str, subperiod:str, k:int):\n",
    "    \"\"\" \n",
    "    Number of authors in a larger time period who have also\n",
    "    made commits in k number of smaller time periods. \n",
    "    \n",
    "    For example, number of authors in a year who have also \n",
    "    committed changes in each month of that year.\n",
    "    \"\"\"\n",
    "    subper = df.ts.dt.to_period(subperiod)\n",
    "    subcols = ['owner_name', 'project_name',\n",
    "               'name', 'email']\n",
    "    subgrp = [subper, 'owner_name', 'project_name', 'name', 'email']\n",
    "    ok = df[subcols].groupby(subgrp).count()\n",
    "    ok = ok.reset_index()\n",
    "    \n",
    "    if period == 'Y':\n",
    "        \n",
    "        ok['year'] = ok.ts.apply(lambda x: x.year)\n",
    "        cols = ['year', 'owner_name', 'project_name', 'name', 'email']\n",
    "        grp = ['year','owner_name','project_name', 'name']\n",
    "        ok = ok[cols].groupby(grp).count()\n",
    "        \n",
    "        ok = ok.reset_index()\n",
    "        ok = ok[['year', 'owner_name', 'project_name', 'email']]\n",
    "        ok.columns = ['ts', 'owner_name', 'project_name', 'mentor_count']\n",
    "        result = ok[ok.mentor_count >= k].groupby(['ts', 'owner_name', 'project_name']).count()\n",
    "        \n",
    "        result = result.reset_index()\n",
    "        return result\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Period '{}' not found\".format(period))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_orgs(df, period):\n",
    "    \"\"\" Number of organizations contributing per time period \"\"\"\n",
    "    email_suffix = ['com','org','ru','edu','dk','id.au','ac',\n",
    "                'de','uk','cz','fr','jp','il','me','net',\n",
    "                'eu', 'pw', 'ch','cn','io','nu','it','ai',\n",
    "               'fi', 'info', 'sk', 'ie', 'ca', 'at', 'pl',\n",
    "               'hu', 'nl', 'works', 'hr', 'se','no', 'blue',\n",
    "               '(none)', 'lt', 'cc', 'si', 'la', 'us', 'gr',\n",
    "               'De','br', 'ro', 'li', 'gov', 'pt', 'is', 'sg',\n",
    "               'vin', 'in', 'be', 'bzh', 'pm', 'xyz', 'fun',\n",
    "               'es', 'systems', 'cx', 'tw','cl', 'lv', 'ne',\n",
    "               'co', 'st', 'ma', 'ws', 'su', 'ORG', 'tk', 'cu',\n",
    "               'COM', 'kr', 'vpc', 'ip', 'danix', 'Com', 're',\n",
    "               'EDU']\n",
    "    pattern = '[A-Za-z\\-\\._0-9\\+]+@(.*)?.({})'.format('|'.join(email_suffix))\n",
    "    pat = re.compile(pattern)\n",
    "    \n",
    "    df['org_name'] = df.email.apply(lambda x: pat.match(x).group(1) if pat.match(x) else np.NaN)\n",
    "    \n",
    "    per = df.ts.dt.to_period(period)\n",
    "    cols = ['owner_name', 'project_name', 'org_name']\n",
    "\n",
    "    result = df[cols].groupby([per, 'owner_name', 'project_name']).count()\n",
    "    result = result.reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a working dataframe\n",
    "\n",
    "This is the dataframe we can use for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>project_name</th>\n",
       "      <th>mentor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>apache</td>\n",
       "      <td>lucene-solr</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>apache</td>\n",
       "      <td>lucene-solr</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>apache</td>\n",
       "      <td>lucene-solr</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>apache</td>\n",
       "      <td>lucene-solr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>torvalds</td>\n",
       "      <td>linux</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ts owner_name project_name  mentor_count\n",
       "0  2002     apache  lucene-solr             4\n",
       "1  2003     apache  lucene-solr             3\n",
       "2  2004     apache  lucene-solr             4\n",
       "3  2005     apache  lucene-solr             5\n",
       "4  2005   torvalds        linux           170"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = num_mentors(df, 'Y', 'M', 6)\n",
    "X_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = num_authors(df, 'Y').reset_index()\n",
    "X_2 = num_mentors(df, 'Y', 'M', 6).reset_index()\n",
    "X_3 = num_orgs(df, 'Y')\n",
    "\n",
    "print(\"X_1 {}, X_2 {}, X_3 {}\".format(X_1.shape, X_2.shape, X_3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_13 = pd.merge(X_1, X_3)\n",
    "X_13.ts  = X_13.ts.apply(lambda x: x.year)\n",
    "X_13.shape[0] == X_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_13.merge(X_2[['ts','owner_name', 'project_name', 'mentor_count']], \n",
    "            how='left', on=['ts','owner_name', 'project_name'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Target vector\n",
    "\n",
    "We're trying to predict velocity for the next time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = df.ts.dt.to_period('Y')\n",
    "cols = ['owner_name', 'project_name', 'lines_added', 'lines_subtracted']\n",
    "grp = [per, 'owner_name', 'project_name']\n",
    "df_target = df[cols].groupby(grp).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target['velocity'] = df_target.lines_added - df_target.lines_subtracted\n",
    "df_target = df_target.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check target and feature dims match: {}\".format(df_target.shape[0] == X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train/val/test splits\n",
    "\n",
    "We can break this out by year and see how things go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "X_train = X[X.ts == 2015].fillna(0.0)\n",
    "y_train = df_target[df_target.ts == 2015].velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "X_test = X[X.ts == 2016].fillna(0.0)\n",
    "y_test = df_target[df_target.ts == 2016].velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val\n",
    "\n",
    "X_val = X[X.ts == 2017].fillna(0.0)\n",
    "y_val = df_target[df_target.ts == 2017].velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking features \n",
    "\n",
    "Before predicting our features, we want to \n",
    "check to see if our features are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['num_authors', 'org_name', 'mentor_count']\n",
    "X_train[cols].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, this is what we call an endogeneity problem. Let's \n",
    "transform the variables and see if the correlation goes down. I \n",
    "think there's a few outliers driving this correlation. Log transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log = (X_train[cols] + 1).apply(np.log)\n",
    "X_train_log.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a little better but I can't sufficiently resolve multicollinearity. I'll\n",
    "run the regression with just the `mentor_count`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Predicting velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train[cols], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$r^2$ for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test[cols], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$r^2$ for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_val[cols], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using a linear regression seems fairly robust to\n",
    "predicting `velocity`. Let's try just one feature since\n",
    "we've got multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['mentor_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train[col], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "\n",
    "reg.score(X_test[col], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "\n",
    "reg.score(X_val[col], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our accuracy drop a bit but not much when \n",
    "multicollinearity is removed. Given that test and validation\n",
    "sets are subsequent years, let's try predicting a subsequent \n",
    "year just for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test[X_test.project_name != 'attic-wink'][col], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we're just as competitive predicting on subsequent years. I think\n",
    "this is probably sufficient for scaling up to Spark tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test[col])\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test[col], y_test,  color='black')\n",
    "plt.plot(X_test[col], y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "This looks like a nice linear relationship that we were able to\n",
    "get out of this data after changing the representation of the data.\n",
    "I think this is ready to scale up. We can show descriptively, examples\n",
    "of the velocity converging to zero. We can forecast future convergence\n",
    "by just using a linear regression. This seems pretty reasonable for\n",
    "a class project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
